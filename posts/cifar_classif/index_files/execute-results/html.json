{
  "hash": "8593c3070980a4c509b93ca71f0cd54a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Classify CIFAR\"\nauthor: \"Julien Combes\"\ndate: \"2025-04-13\"\ncategories: [DeepLearning, code, ImageClassification, ComputerVision, ENG]\nimage: \"image.jpg\"\n---\n\n\nCIFAR is a trivial problem in image classification.\nWe will be using Pytorch and lightning in order to do the training.\n\n\nThe advantage of this approach, is that the workflow can be done locally\non the cpu of your computer or on ten H100 of any cloud you could get access to. \n\n[Lightning](https://lightning.ai/docs/pytorch/stable/) handles the location of data and optimization related objects (model, optimizer, scheduler etc...), and last be not least, the metrics computation done with [torchmetrics](https://lightning.ai/docs/torchmetrics/stable/).\n\nThe metrics have the gathering across gpus/devices already implemented so you just have to decide of which ones you want to add to your project. If some computations are not already present in the library, you can [add your own metric](https://lightning.ai/docs/torchmetrics/stable/pages/implement.html) very easily.\n\n\n## The data\n\n::: {#f7c1d7cc .cell execution_count=1}\n``` {.python .cell-code}\nimport torchvision\nimport torch\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport numpy as np\nimport os\n#Â to make the transform usable by torchvision dataset it needs to be a function that takes an image as input and return an image as well\n\ndatarootdir = os.environ.get(\"DATA_ROOTPATH\", \"data\")\n\ndef train_trans(image)->torch.tensor:\n    transform = A.Compose([\n        A.HorizontalFlip(),\n        A.Normalize(),\n        ToTensorV2()\n    ]) \n\n    transformed = transform(image = np.array(image))\n\n    return transformed[\"image\"]\n\ndef test_trans(image)->torch.tensor:\n    transform = A.Compose([\n        A.Normalize(),\n        ToTensorV2()\n    ]) \n\n    transformed = transform(image = np.array(image))\n\n    return transformed[\"image\"]\n\ntrain_set = torchvision.datasets.CIFAR10(\n    root=\"data\", \n    download=True, \n    train=True,\n    transform=train_trans)\n\nval_set = torchvision.datasets.CIFAR10(\n    root=\"data\", \n    download=True, \n    train=False,\n    transform=test_trans)\n\ntrain_loader= torch.utils.data.DataLoader(\n    train_set,\n    # shuffle=True,\n    sampler = torch.utils.data.SubsetRandomSampler(np.random.choice(len(train_set), 10000)),\n    batch_size=64,\n    num_workers=5,\n\n)\n\nval_loader= torch.utils.data.DataLoader(\n    val_set,\n    shuffle=False,\n    batch_size=64*2,\n    num_workers=5,\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0.00/170M [00:00<?, ?B/s]\r  0%|          | 32.8k/170M [00:00<13:31, 210kB/s]\r  0%|          | 131k/170M [00:00<05:30, 516kB/s] \r  0%|          | 393k/170M [00:00<02:35, 1.09MB/s]\r  1%|          | 885k/170M [00:00<01:15, 2.26MB/s]\r  1%|          | 1.87M/170M [00:00<00:38, 4.41MB/s]\r  2%|â–         | 2.72M/170M [00:00<00:29, 5.62MB/s]\r  2%|â–         | 3.74M/170M [00:00<00:26, 6.27MB/s]\r  3%|â–Ž         | 4.75M/170M [00:00<00:22, 7.34MB/s]\r  3%|â–Ž         | 5.57M/170M [00:01<00:22, 7.29MB/s]\r  4%|â–         | 6.62M/170M [00:01<00:20, 8.09MB/s]\r  4%|â–         | 7.54M/170M [00:01<00:20, 8.02MB/s]\r  5%|â–         | 8.42M/170M [00:01<00:19, 8.20MB/s]\r  5%|â–Œ         | 9.27M/170M [00:01<00:23, 6.97MB/s]\r  6%|â–Œ         | 10.0M/170M [00:01<00:25, 6.22MB/s]\r  6%|â–‹         | 11.0M/170M [00:01<00:23, 6.93MB/s]\r  7%|â–‹         | 11.7M/170M [00:02<00:26, 6.02MB/s]\r  7%|â–‹         | 12.4M/170M [00:02<00:28, 5.61MB/s]\r  8%|â–Š         | 13.0M/170M [00:02<00:29, 5.41MB/s]\r  8%|â–Š         | 13.7M/170M [00:02<00:30, 5.10MB/s]\r  9%|â–Š         | 14.5M/170M [00:02<00:27, 5.62MB/s]\r  9%|â–‰         | 15.2M/170M [00:02<00:27, 5.68MB/s]\r 10%|â–‰         | 16.3M/170M [00:02<00:22, 6.89MB/s]\r 10%|â–ˆ         | 17.2M/170M [00:02<00:20, 7.39MB/s]\r 11%|â–ˆ         | 18.0M/170M [00:02<00:20, 7.51MB/s]\r 11%|â–ˆ         | 18.8M/170M [00:03<00:20, 7.28MB/s]\r 12%|â–ˆâ–        | 19.9M/170M [00:03<00:19, 7.92MB/s]\r 12%|â–ˆâ–        | 20.8M/170M [00:03<00:18, 8.23MB/s]\r 13%|â–ˆâ–Ž        | 21.9M/170M [00:03<00:17, 8.52MB/s]\r 13%|â–ˆâ–Ž        | 22.9M/170M [00:03<00:17, 8.32MB/s]\r 14%|â–ˆâ–        | 24.0M/170M [00:03<00:17, 8.53MB/s]\r 15%|â–ˆâ–        | 24.8M/170M [00:03<00:17, 8.44MB/s]\r 15%|â–ˆâ–Œ        | 25.7M/170M [00:03<00:17, 8.17MB/s]\r 16%|â–ˆâ–Œ        | 26.6M/170M [00:04<00:17, 8.35MB/s]\r 16%|â–ˆâ–Œ        | 27.6M/170M [00:04<00:16, 8.58MB/s]\r 17%|â–ˆâ–‹        | 28.4M/170M [00:04<00:16, 8.45MB/s]\r 17%|â–ˆâ–‹        | 29.3M/170M [00:04<00:16, 8.46MB/s]\r 18%|â–ˆâ–Š        | 30.2M/170M [00:04<00:16, 8.26MB/s]\r 18%|â–ˆâ–Š        | 31.1M/170M [00:04<00:16, 8.41MB/s]\r 19%|â–ˆâ–‰        | 32.2M/170M [00:04<00:16, 8.45MB/s]\r 20%|â–ˆâ–‰        | 33.3M/170M [00:04<00:16, 8.57MB/s]\r 20%|â–ˆâ–ˆ        | 34.1M/170M [00:04<00:15, 8.61MB/s]\r 21%|â–ˆâ–ˆ        | 35.1M/170M [00:05<00:16, 8.40MB/s]\r 21%|â–ˆâ–ˆ        | 35.9M/170M [00:05<00:15, 8.43MB/s]\r 22%|â–ˆâ–ˆâ–       | 36.9M/170M [00:05<00:16, 8.29MB/s]\r 22%|â–ˆâ–ˆâ–       | 37.9M/170M [00:05<00:15, 8.61MB/s]\r 23%|â–ˆâ–ˆâ–Ž       | 39.0M/170M [00:05<00:15, 8.40MB/s]\r 24%|â–ˆâ–ˆâ–Ž       | 40.1M/170M [00:05<00:15, 8.65MB/s]\r 24%|â–ˆâ–ˆâ–       | 41.0M/170M [00:05<00:15, 8.61MB/s]\r 25%|â–ˆâ–ˆâ–       | 41.9M/170M [00:05<00:15, 8.37MB/s]\r 25%|â–ˆâ–ˆâ–Œ       | 42.9M/170M [00:05<00:14, 8.55MB/s]\r 26%|â–ˆâ–ˆâ–Œ       | 44.0M/170M [00:06<00:14, 8.60MB/s]\r 26%|â–ˆâ–ˆâ–‹       | 44.9M/170M [00:06<00:14, 8.56MB/s]\r 27%|â–ˆâ–ˆâ–‹       | 45.8M/170M [00:06<00:14, 8.32MB/s]\r 27%|â–ˆâ–ˆâ–‹       | 46.8M/170M [00:06<00:14, 8.73MB/s]\r 28%|â–ˆâ–ˆâ–Š       | 47.6M/170M [00:06<00:14, 8.49MB/s]\r 28%|â–ˆâ–ˆâ–Š       | 48.5M/170M [00:06<00:15, 8.10MB/s]\r 29%|â–ˆâ–ˆâ–‰       | 49.5M/170M [00:06<00:14, 8.47MB/s]\r 30%|â–ˆâ–ˆâ–‰       | 50.4M/170M [00:06<00:14, 8.17MB/s]\r 30%|â–ˆâ–ˆâ–ˆ       | 51.5M/170M [00:06<00:14, 8.07MB/s]\r 31%|â–ˆâ–ˆâ–ˆ       | 52.7M/170M [00:07<00:14, 8.38MB/s]\r 32%|â–ˆâ–ˆâ–ˆâ–      | 53.7M/170M [00:07<00:12, 9.00MB/s]\r 32%|â–ˆâ–ˆâ–ˆâ–      | 54.7M/170M [00:07<00:13, 8.66MB/s]\r 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 55.6M/170M [00:07<00:13, 8.73MB/s]\r 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 56.5M/170M [00:07<00:13, 8.39MB/s]\r 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 57.3M/170M [00:07<00:14, 7.99MB/s]\r 34%|â–ˆâ–ˆâ–ˆâ–      | 58.4M/170M [00:07<00:13, 8.29MB/s]\r 35%|â–ˆâ–ˆâ–ˆâ–      | 59.5M/170M [00:07<00:13, 8.53MB/s]\r 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 60.6M/170M [00:08<00:12, 8.60MB/s]\r 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 61.6M/170M [00:08<00:12, 8.90MB/s]\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 62.5M/170M [00:08<00:12, 8.97MB/s]\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 63.4M/170M [00:08<00:12, 8.33MB/s]\r 38%|â–ˆâ–ˆâ–ˆâ–Š      | 64.3M/170M [00:08<00:12, 8.26MB/s]\r 38%|â–ˆâ–ˆâ–ˆâ–Š      | 65.2M/170M [00:08<00:12, 8.30MB/s]\r 39%|â–ˆâ–ˆâ–ˆâ–‰      | 66.4M/170M [00:08<00:12, 8.45MB/s]\r 40%|â–ˆâ–ˆâ–ˆâ–‰      | 67.5M/170M [00:08<00:11, 8.63MB/s]\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 68.4M/170M [00:08<00:11, 8.65MB/s]\r 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 69.3M/170M [00:09<00:11, 8.60MB/s]\r 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 70.3M/170M [00:09<00:11, 9.09MB/s]\r 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71.2M/170M [00:09<00:11, 8.69MB/s]\r 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 72.2M/170M [00:09<00:10, 8.97MB/s]\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 73.1M/170M [00:09<00:11, 8.73MB/s]\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 74.1M/170M [00:09<00:10, 8.87MB/s]\r 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 75.0M/170M [00:09<00:11, 8.59MB/s]\r 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 76.1M/170M [00:09<00:11, 8.47MB/s]\r 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 77.2M/170M [00:09<00:11, 8.22MB/s]\r 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 78.3M/170M [00:10<00:10, 8.48MB/s]\r 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 79.2M/170M [00:10<00:10, 8.50MB/s]\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 80.2M/170M [00:10<00:10, 8.45MB/s]\r 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 81.1M/170M [00:10<00:10, 8.63MB/s]\r 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 82.0M/170M [00:10<00:10, 8.23MB/s]\r 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 83.0M/170M [00:10<00:09, 8.84MB/s]\r 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 83.9M/170M [00:10<00:10, 8.12MB/s]\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 84.8M/170M [00:10<00:10, 8.29MB/s]\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 85.7M/170M [00:10<00:10, 8.32MB/s]\r 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 86.5M/170M [00:11<00:10, 8.02MB/s]\r 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87.5M/170M [00:11<00:09, 8.61MB/s]\r 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 88.4M/170M [00:11<00:09, 8.23MB/s]\r 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 89.5M/170M [00:11<00:09, 8.51MB/s]\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 90.4M/170M [00:11<00:10, 8.01MB/s]\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 91.2M/170M [00:11<00:10, 7.81MB/s]\r 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 92.0M/170M [00:11<00:10, 7.51MB/s]\r 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 92.8M/170M [00:12<00:14, 5.29MB/s]\r 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 93.6M/170M [00:12<00:13, 5.57MB/s]\r 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 94.2M/170M [00:12<00:21, 3.61MB/s]\r 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 94.8M/170M [00:12<00:20, 3.65MB/s]\r 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 95.2M/170M [00:12<00:21, 3.56MB/s]\r 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 95.6M/170M [00:13<00:29, 2.53MB/s]\r 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 96.0M/170M [00:13<00:32, 2.26MB/s]\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 96.5M/170M [00:13<00:35, 2.09MB/s]\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 96.9M/170M [00:13<00:31, 2.36MB/s]\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 97.4M/170M [00:13<00:31, 2.31MB/s]\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 97.9M/170M [00:14<00:25, 2.80MB/s]\r 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 98.3M/170M [00:14<00:24, 3.01MB/s]\r 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 98.9M/170M [00:14<00:20, 3.46MB/s]\r 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 99.5M/170M [00:14<00:18, 3.84MB/s]\r 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 100M/170M [00:14<00:16, 4.25MB/s] \r 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 101M/170M [00:14<00:14, 4.74MB/s]\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 101M/170M [00:14<00:14, 4.69MB/s]\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 102M/170M [00:14<00:13, 5.03MB/s]\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 103M/170M [00:15<00:12, 5.46MB/s]\r 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 104M/170M [00:15<00:11, 5.74MB/s]\r 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 104M/170M [00:15<00:10, 6.03MB/s]\r 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 105M/170M [00:15<00:11, 5.84MB/s]\r 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 106M/170M [00:15<00:10, 6.33MB/s]\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 107M/170M [00:15<00:09, 6.88MB/s]\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 108M/170M [00:15<00:09, 6.78MB/s]\r 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 108M/170M [00:15<00:09, 6.71MB/s]\r 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 109M/170M [00:15<00:09, 6.45MB/s]\r 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 110M/170M [00:16<00:08, 6.91MB/s]\r 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 111M/170M [00:16<00:08, 7.06MB/s]\r 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 111M/170M [00:16<00:08, 6.79MB/s]\r 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 112M/170M [00:16<00:07, 7.42MB/s]\r 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 113M/170M [00:16<00:08, 7.08MB/s]\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 114M/170M [00:16<00:08, 7.02MB/s]\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 115M/170M [00:16<00:08, 6.63MB/s]\r 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 115M/170M [00:16<00:07, 7.12MB/s]\r 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 116M/170M [00:16<00:08, 6.78MB/s]\r 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 117M/170M [00:17<00:07, 7.06MB/s]\r 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 118M/170M [00:17<00:07, 7.24MB/s]\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 119M/170M [00:17<00:06, 7.62MB/s]\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 120M/170M [00:17<00:06, 7.67MB/s]\r 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 121M/170M [00:17<00:07, 7.06MB/s]\r 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 122M/170M [00:17<00:06, 7.31MB/s]\r 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 123M/170M [00:17<00:06, 7.66MB/s]\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 124M/170M [00:17<00:06, 7.43MB/s]\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 124M/170M [00:18<00:06, 7.62MB/s]\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 125M/170M [00:18<00:05, 7.60MB/s]\r 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 126M/170M [00:18<00:05, 7.44MB/s]\r 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 127M/170M [00:18<00:06, 7.07MB/s]\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 128M/170M [00:18<00:05, 7.63MB/s]\r 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 129M/170M [00:18<00:05, 7.75MB/s]\r 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 130M/170M [00:18<00:05, 7.68MB/s]\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 131M/170M [00:18<00:05, 7.67MB/s]\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 131M/170M [00:19<00:06, 6.41MB/s]\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 132M/170M [00:19<00:06, 5.83MB/s]\r 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 133M/170M [00:19<00:07, 5.29MB/s]\r 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 133M/170M [00:19<00:07, 5.12MB/s]\r 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 134M/170M [00:19<00:06, 5.63MB/s]\r 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 135M/170M [00:19<00:05, 6.01MB/s]\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 136M/170M [00:19<00:05, 6.04MB/s]\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 136M/170M [00:19<00:05, 6.09MB/s]\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 137M/170M [00:20<00:04, 6.83MB/s]\r 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 138M/170M [00:20<00:04, 6.85MB/s]\r 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 139M/170M [00:20<00:04, 7.40MB/s]\r 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 140M/170M [00:20<00:04, 6.84MB/s]\r 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 140M/170M [00:20<00:04, 7.19MB/s]\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 141M/170M [00:20<00:04, 6.94MB/s]\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 142M/170M [00:20<00:04, 7.09MB/s]\r 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 143M/170M [00:20<00:04, 5.92MB/s]\r 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 143M/170M [00:21<00:05, 5.11MB/s]\r 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 144M/170M [00:21<00:05, 5.01MB/s]\r 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 145M/170M [00:21<00:05, 4.92MB/s]\r 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 145M/170M [00:21<00:05, 4.95MB/s]\r 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 146M/170M [00:21<00:05, 4.76MB/s]\r 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 146M/170M [00:21<00:05, 4.60MB/s]\r 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 147M/170M [00:21<00:04, 4.75MB/s]\r 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 147M/170M [00:21<00:04, 4.87MB/s]\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 148M/170M [00:22<00:04, 4.70MB/s]\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 149M/170M [00:22<00:04, 4.79MB/s]\r 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 149M/170M [00:22<00:04, 4.67MB/s]\r 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 150M/170M [00:22<00:04, 4.77MB/s]\r 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 150M/170M [00:22<00:04, 4.73MB/s]\r 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 151M/170M [00:22<00:04, 4.75MB/s]\r 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 152M/170M [00:22<00:03, 4.78MB/s]\r 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 152M/170M [00:22<00:03, 4.89MB/s]\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 153M/170M [00:23<00:03, 4.82MB/s]\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 153M/170M [00:23<00:03, 4.98MB/s]\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 154M/170M [00:23<00:03, 5.15MB/s]\r 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 155M/170M [00:23<00:03, 4.91MB/s]\r 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 155M/170M [00:23<00:03, 5.01MB/s]\r 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 156M/170M [00:23<00:02, 5.11MB/s]\r 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 156M/170M [00:23<00:02, 5.28MB/s]\r 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 157M/170M [00:23<00:02, 4.94MB/s]\r 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 158M/170M [00:23<00:02, 4.93MB/s]\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 158M/170M [00:24<00:02, 5.00MB/s]\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 159M/170M [00:24<00:02, 5.29MB/s]\r 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 160M/170M [00:24<00:02, 5.31MB/s]\r 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 160M/170M [00:24<00:01, 5.63MB/s]\r 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 161M/170M [00:24<00:01, 5.62MB/s]\r 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 162M/170M [00:24<00:01, 6.14MB/s]\r 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 163M/170M [00:24<00:01, 6.71MB/s]\r 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 164M/170M [00:24<00:00, 7.45MB/s]\r 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 164M/170M [00:24<00:00, 7.70MB/s]\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 165M/170M [00:25<00:00, 7.70MB/s]\r 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 166M/170M [00:25<00:00, 8.10MB/s]\r 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 167M/170M [00:25<00:00, 8.41MB/s]\r 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 168M/170M [00:25<00:00, 8.27MB/s]\r 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 169M/170M [00:25<00:00, 8.42MB/s]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 170M/170M [00:25<00:00, 8.44MB/s]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:25<00:00, 6.63MB/s]\n```\n:::\n:::\n\n\n## The model\n\n::: {#3eb37761 .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nimport lightning as L\nfrom typing import Optional, List\nimport torchmetrics\nfrom omegaconf import DictConfig, OmegaConf\n\nclass ClassificationModule(L.LightningModule):\n    def __init__(\n        self, \n        categories :List[str],\n        config:DictConfig,\n        model: Optional[torch.nn.Module] = None, \n        ):\n        \n        super().__init__()\n        self.categories = categories\n        num_classes = len(categories)\n        self.config = config\n        \n        self.model = model\n        if model is None:\n            self.model = torchvision.models.resnet18(num_classes=num_classes)\n\n        self.criterion = torch.nn.CrossEntropyLoss()\n\n        metrics = torchmetrics.MetricCollection([\n            torchmetrics.classification.Accuracy(task = \"multiclass\", num_classes = num_classes),\n            torchmetrics.F1Score(task = \"multiclass\", num_classes = num_classes),\n            torchmetrics.Precision(task = \"multiclass\", num_classes = num_classes),\n            torchmetrics.Recall(task = \"multiclass\", num_classes = num_classes),\n            torchmetrics.CalibrationError(task = \"multiclass\", num_classes = num_classes),\n        ])\n\n        self.train_metric = metrics.clone(prefix=\"Train/\")\n        self.val_metrics = metrics.clone(prefix=\"Validation/\")\n        self.test_metrics = metrics.clone(prefix=\"Test/\")\n\n        self.per_category_metrics = torchmetrics.MetricCollection([\n            torchmetrics.classification.Accuracy(task = \"multiclass\", num_classes = num_classes, average = None),\n            torchmetrics.F1Score(task = \"multiclass\", num_classes = num_classes, average = None),\n            torchmetrics.Precision(task = \"multiclass\", num_classes = num_classes, average = None),\n            torchmetrics.Recall(task = \"multiclass\", num_classes = num_classes, average = None),\n        ])\n\n    def forward(self, X):\n        return self.model(X)\n\n    def configure_optimizers(self):\n\n        optimizer = torch.optim.Adam(self.parameters(), lr = self.config.lr, weight_decay=1e-5)\n\n        #Â you can add a scheduler here as well and return it as \n        # return [optimizer], [scheduler]\n        # \n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        images, targets = batch\n\n        outputs = self(images)\n\n        loss = self.criterion(outputs, targets)\n        \n        self.train_metric(outputs, targets)\n\n        self.log(\"Train/Loss\",loss, on_epoch=True, on_step=True, prog_bar=True)\n\n        return loss\n    \n    def on_train_epoch_end(self):\n\n        train_metrics=  self.train_metric.compute()\n\n        self.log_dict(train_metrics)\n\n        self.train_metric.reset()\n    \n    def validation_step(self, batch, batch_idx):\n        images, targets = batch\n\n        outputs = self(images)\n\n        loss = self.criterion(outputs, targets)\n        self.log(\"Validation/Loss\", loss, on_epoch=True, on_step=False)\n\n        self.val_metrics(outputs, targets)\n        self.per_category_metrics(outputs, targets)\n\n        \n    \n    def on_validation_epoch_end(self):\n\n        val_metrics =  self.val_metrics.compute()\n\n        self.log_dict(val_metrics)\n\n        m = self.per_category_metrics.compute()\n        for mname, mresults in m.items():\n            for i, catname in enumerate(self.categories):\n                self.log(f\"Validation/{mname}_{catname}\", mresults[i])\n\n        self.val_metrics.reset()\n        self.per_category_metrics.reset()\n    \n\n    def test_step(self, batch, batch_idx):\n        images, targets = batch\n\n        outputs = self(images)\n\n        loss = self.criterion(outputs, targets)\n        self.log(\"Test/Loss\", loss, on_epoch=True, on_step=False)\n\n        self.test_metrics(outputs, targets)\n        self.per_category_metrics(outputs, targets)\n\n        \n    \n    def on_test_epoch_end(self):\n\n        test_metrics =  self.test_metrics.compute()\n\n        self.log_dict(test_metrics)\n        m = self.per_category_metrics.compute()\n        for mname, mresults in m.items():\n            for i, catname in enumerate(self.categories):\n                self.log(f\"Validation/{mname}_{catname}\", mresults[i])\n\n        self.test_metrics.reset()\n        self.per_category_metrics.reset()\n\n\nconfig = OmegaConf.create({\n    \"lr\": 1e-5\n})\n\nmodel = ClassificationModule(\n    categories=train_set.classes,\n    config=config\n)\n\n```\n:::\n\n\n##Â Use everything for train\n\n::: {#efd9e3dd .cell execution_count=3}\n``` {.python .cell-code}\ntrainer=  L.Trainer(\n    max_epochs=3,\n    precision = \"16-mixed\",\n    enable_checkpointing=True,\n    num_sanity_val_steps=2,\n    log_every_n_steps=50,\n    check_val_every_n_epoch=1,\n)\n\n# trainer.fit(\n#     model,\n#     train_loader,\n#     val_loader\n# )\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 16bit Automatic Mixed Precision (AMP)\nðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/home/E097600/these/JulienCombes/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n```\n:::\n:::\n\n\n## And it is Done ! \n\nThe weights of the model are saved with the config that produced them.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}