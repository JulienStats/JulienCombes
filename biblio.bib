@misc{angelopoulosImagetoImageRegressionDistributionFree2022,
  title = {Image-to-{{Image Regression}} with {{Distribution-Free Uncertainty Quantification}} and {{Applications}} in {{Imaging}}},
  author = {Angelopoulos, Anastasios N. and Kohli, Amit P. and Bates, Stephen and Jordan, Michael I. and Malik, Jitendra and Alshaabi, Thayer and Upadhyayula, Srigokul and Romano, Yaniv},
  year = 2022,
  month = feb,
  number = {arXiv:2202.05265},
  eprint = {2202.05265},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.05265},
  urldate = {2025-12-06},
  abstract = {Image-to-image regression is an important learning task, used frequently in biological imaging. Current algorithms, however, do not generally offer statistical guarantees that protect against a model's mistakes and hallucinations. To address this, we develop uncertainty quantification techniques with rigorous statistical guarantees for image-to-image regression problems. In particular, we show how to derive uncertainty intervals around each pixel that are guaranteed to contain the true value with a user-specified confidence probability. Our methods work in conjunction with any base machine learning model, such as a neural network, and endow it with formal mathematical guarantees -- regardless of the true unknown data distribution or choice of model. Furthermore, they are simple to implement and computationally inexpensive. We evaluate our procedure on three image-to-image regression tasks: quantitative phase microscopy, accelerated magnetic resonance imaging, and super-resolution transmission electron microscopy of a Drosophila melanogaster brain.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/home/arthings/Zotero/storage/78XTATSU/Angelopoulos et al. - 2022 - Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imag.pdf;/home/arthings/Zotero/storage/32JQX3NR/2202.html}
}

@misc{angelopoulosTheoreticalFoundationsConformal2025,
  title = {Theoretical {{Foundations}} of {{Conformal Prediction}}},
  author = {Angelopoulos, Anastasios N. and Barber, Rina Foygel and Bates, Stephen},
  year = 2025,
  month = jun,
  number = {arXiv:2411.11824},
  eprint = {2411.11824},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.11824},
  urldate = {2025-12-06},
  abstract = {This book is about conformal prediction and related inferential techniques that build on permutation tests and exchangeability. These techniques are useful in a diverse array of tasks, including hypothesis testing and providing uncertainty quantification guarantees for machine learning systems. Much of the current interest in conformal prediction is due to its ability to integrate into complex machine learning workflows, solving the problem of forming prediction sets without any assumptions on the form of the data generating distribution. Since contemporary machine learning algorithms have generally proven difficult to analyze directly, conformal prediction's main appeal is its ability to provide formal, finite-sample guarantees when paired with such methods. The goal of this book is to teach the reader about the fundamental technical arguments that arise when researching conformal prediction and related questions in distribution-free inference. Many of these proof strategies, especially the more recent ones, are scattered among research papers, making it difficult for researchers to understand where to look, which results are important, and how exactly the proofs work. We hope to bridge this gap by curating what we believe to be some of the most important results in the literature and presenting their proofs in a unified language, with illustrations, and with an eye towards pedagogy.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/arthings/Zotero/storage/L49VDTHB/Angelopoulos et al. - 2025 - Theoretical Foundations of Conformal Prediction.pdf;/home/arthings/Zotero/storage/67V9SMNP/2411.html}
}

@misc{angelopoulosUncertaintySetsImage2022,
  title = {Uncertainty {{Sets}} for {{Image Classifiers}} Using {{Conformal Prediction}}},
  author = {Angelopoulos, Anastasios and Bates, Stephen and Malik, Jitendra and Jordan, Michael I.},
  year = 2022,
  month = sep,
  number = {arXiv:2009.14193},
  eprint = {2009.14193},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2009.14193},
  urldate = {2025-12-06},
  abstract = {Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network's probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90\%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/home/arthings/Zotero/storage/VAEX53HS/Angelopoulos et al. - 2022 - Uncertainty Sets for Image Classifiers using Conformal Prediction.pdf;/home/arthings/Zotero/storage/KQV74Z2S/2009.html}
}

@misc{ashDeepBatchActive2020,
  title = {Deep {{Batch Active Learning}} by {{Diverse}}, {{Uncertain Gradient Lower Bounds}}},
  author = {Ash, Jordan T. and Zhang, Chicheng and Krishnamurthy, Akshay and Langford, John and Agarwal, Alekh},
  year = 2020,
  month = feb,
  number = {arXiv:1906.03671},
  eprint = {1906.03671},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1906.03671},
  urldate = {2025-12-06},
  abstract = {We design a new algorithm for batch active learning with deep neural network models. Our algorithm, Batch Active learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high-magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between diversity and uncertainty without requiring any hand-tuned hyperparameters. We show that while other approaches sometimes succeed for particular batch sizes or architectures, BADGE consistently performs as well or better, making it a versatile option for practical active learning problems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/arthings/Zotero/storage/N66D72QS/Ash et al. - 2020 - Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds.pdf;/home/arthings/Zotero/storage/8VMDEXE7/1906.html}
}

@misc{brunekreefKandinskyConformalPrediction2023,
  title = {Kandinsky {{Conformal Prediction}}: {{Efficient Calibration}} of {{Image Segmentation Algorithms}}},
  shorttitle = {Kandinsky {{Conformal Prediction}}},
  author = {Brunekreef, Joren and Marcus, Eric and Sheombarsing, Ray and Sonke, Jan-Jakob and Teuwen, Jonas},
  year = 2023,
  month = nov,
  number = {arXiv:2311.11837},
  eprint = {2311.11837},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.11837},
  urldate = {2025-12-06},
  abstract = {Image segmentation algorithms can be understood as a collection of pixel classifiers, for which the outcomes of nearby pixels are correlated. Classifier models can be calibrated using Inductive Conformal Prediction, but this requires holding back a sufficiently large calibration dataset for computing the distribution of non-conformity scores of the model's predictions. If one only requires only marginal calibration on the image level, this calibration set consists of all individual pixels in the images available for calibration. However, if the goal is to attain proper calibration for each individual pixel classifier, the calibration set consists of individual images. In a scenario where data are scarce (such as the medical domain), it may not always be possible to set aside sufficiently many images for this pixel-level calibration. The method we propose, dubbed ``Kandinsky calibration'', makes use of the spatial structure present in the distribution of natural images to simultaneously calibrate the classifiers of ``similar'' pixels. This can be seen as an intermediate approach between marginal (imagewise) and conditional (pixelwise) calibration, where non-conformity scores are aggregated over similar image regions, thereby making more efficient use of the images available for calibration. We run experiments on segmentation algorithms trained and calibrated on subsets of the public MS-COCO and Medical Decathlon datasets, demonstrating that Kandinsky calibration method can significantly improve the coverage. When compared to both pixelwise and imagewise calibration on little data, the Kandinsky method achieves much lower coverage errors, indicating the data efficiency of the Kandinsky calibration.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/arthings/Zotero/storage/4DYAGA2T/Brunekreef et al. - 2023 - Kandinsky Conformal Prediction Efficient Calibration of Image Segmentation Algorithms.pdf;/home/arthings/Zotero/storage/EEMEQ953/2311.html}
}

@misc{dingClassConditionalConformalPrediction2023,
  title = {Class-{{Conditional Conformal Prediction}} with {{Many Classes}}},
  author = {Ding, Tiffany and Angelopoulos, Anastasios N. and Bates, Stephen and Jordan, Michael I. and Tibshirani, Ryan J.},
  year = 2023,
  month = oct,
  number = {arXiv:2306.09335},
  eprint = {2306.09335},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.09335},
  urldate = {2025-12-06},
  abstract = {Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-specified probability. In many classification problems, we would like to obtain a stronger guarantee--that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. For the latter goal, existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction that clusters together classes having "similar" conformal scores and performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set size metrics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/arthings/Zotero/storage/TE5FN92V/Ding et al. - 2023 - Class-Conditional Conformal Prediction with Many Classes.pdf;/home/arthings/Zotero/storage/BH2RKYBM/2306.html}
}

@misc{dingConformalPredictionLongTailed2025,
  title = {Conformal {{Prediction}} for {{Long-Tailed Classification}}},
  author = {Ding, Tiffany and Fermanian, Jean-Baptiste and Salmon, Joseph},
  year = 2025,
  month = oct,
  number = {arXiv:2507.06867},
  eprint = {2507.06867},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.06867},
  urldate = {2025-12-06},
  abstract = {Many real-world classification problems, such as plant identification, have extremely long-tailed class distributions. In order for prediction sets to be useful in such settings, they should (i) provide good class-conditional coverage, ensuring that rare classes are not systematically omitted from the prediction sets, and (ii) be a reasonable size, allowing users to easily verify candidate labels. Unfortunately, existing conformal prediction methods, when applied to the long-tailed setting, force practitioners to make a binary choice between small sets with poor class-conditional coverage or sets with very good class-conditional coverage but that are extremely large. We propose methods with guaranteed marginal coverage that smoothly trade off between set size and class-conditional coverage. First, we introduce a new conformal score function called prevalence-adjusted softmax that targets macro-coverage, a relaxed notion of class-conditional coverage. Second, we propose a new procedure that interpolates between marginal and class-conditional conformal prediction by linearly interpolating their conformal score thresholds. We demonstrate our methods on Pl@ntNet-300K and iNaturalist-2018, two long-tailed image datasets with 1,081 and 8,142 classes, respectively.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/arthings/Zotero/storage/2INWLC8J/Ding et al. - 2025 - Conformal Prediction for Long-Tailed Classification.pdf;/home/arthings/Zotero/storage/HBETEFA8/2507.html}
}

@inproceedings{dupasMEFAMultimodalImage2025,
  title = {{{MEFA}}: {{Multimodal Image Early Fusion}} with {{Attention Module}} for {{Pedestrian}} and {{Vehicle Detection}}},
  shorttitle = {{{MEFA}}},
  booktitle = {{{VISAPP}} 2025 - 20th {{International Conference}} on {{Computer Vision Theory}} and {{Applications}}},
  author = {Dupas, Yoann and Hotel, Olivier and Lefebvre, Gr{\'e}goire and Cerin, Christophe},
  year = 2025,
  month = feb,
  pages = {610--617},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Porto, Portugal},
  doi = {10.5220/0013236000003912},
  urldate = {2025-12-06},
  abstract = {Pedestrian and vehicle detection represents a significant challenge in autonomous driving, particularly in adverse weather conditions. Multimodal image fusion addresses this challenge. This paper proposes a new early-fusion attention-based approach from visible, infrared, and LiDAR images, designated as MEFA (Multimodal image Early Fusion with Attention). In this study, we compare our MEFA proposal with a channel-wise concatenation early-fusion approach. When coupled with YOLOv8 or RT-DETRv1 for pedestrian and vehicle detection, our contribution is promising in adverse weather conditions (i.e. rainy days or foggy nights). Furthermore, our MEFA proposal demonstrated superior mAP accuracy on the DENSE dataset.},
  file = {/home/arthings/Zotero/storage/S63U22DX/Dupas et al. - 2025 - MEFA Multimodal Image Early Fusion with Attention Module for Pedestrian and Vehicle Detection.pdf}
}

@misc{falkMoreCarbonCradletoGrave2025,
  title = {More than {{Carbon}}: {{Cradle-to-Grave}} Environmental Impacts of {{GenAI}} Training on the {{Nvidia A100 GPU}}},
  shorttitle = {More than {{Carbon}}},
  author = {Falk, Sophia and Ekchajzer, David and Pirson, Thibault and {Lees-Perasso}, Etienne and Wattiez, Augustin and {Biber-Freudenberger}, Lisa and Luccioni, Sasha and van Wynsberghe, Aimee},
  year = 2025,
  month = aug,
  number = {arXiv:2509.00093},
  eprint = {2509.00093},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2509.00093},
  urldate = {2025-12-06},
  abstract = {The rapid expansion of AI has intensified concerns about its environmental sustainability. Yet, current assessments predominantly focus on operational carbon emissions using secondary data or estimated values, overlooking environmental impacts in other life cycle stages. This study presents the first comprehensive multi-criteria life cycle assessment (LCA) of AI training, examining 16 environmental impact categories based on detailed primary data collection of the Nvidia A100 SXM 40GB GPU. The LCA results for training BLOOM reveal that the use phase dominates 11 of 16 impact categories including climate change (96\textbackslash\%), while manufacturing dominates the remaining 5 impact categories including human toxicity, cancer (99\textbackslash\%) and mineral and metal depletion (85\textbackslash\%). For training GPT-4, the use phase dominates 10 of 16 impact categories, contributing about 96\textbackslash\% to both the climate change and resource use, fossils category. The manufacturing stage dominates 6 of 16 impact categories including human toxicity, cancer (94\textbackslash\%) and eutrophication, freshwater (81\textbackslash\%). Assessing the cradle-to-gate environmental impact distribution across the GPU components reveals that the GPU chip is the largest contributor across 10 of 16 of impact categories and shows particularly pronounced contributions to climate change (81\textbackslash\%) and resource use, fossils (80\textbackslash\%). While primary data collection results in modest changes in carbon estimates compared to database-derived estimates, substantial variations emerge in other categories. Most notably, minerals and metals depletion increases by 33\textbackslash\%, demonstrating the critical importance of primary data for non-carbon accounting. This multi-criteria analysis expands the Sustainable AI discourse beyond operational carbon emissions, challenging current sustainability narratives and highlighting the need for policy frameworks addressing the full spectrum of AI's environmental impact.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/home/arthings/Zotero/storage/9T86IRYQ/Falk et al. - 2025 - More than Carbon Cradle-to-Grave environmental impacts of GenAI training on the Nvidia A100 GPU.pdf;/home/arthings/Zotero/storage/8SD2GR96/2509.html}
}

@inproceedings{galDeepBayesianActive2017,
  title = {Deep {{Bayesian}} Active Learning with Image Data},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}} - {{Volume}} 70},
  author = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  year = 2017,
  month = aug,
  series = {{{ICML}}'17},
  pages = {1183--1192},
  publisher = {JMLR.org},
  address = {Sydney, NSW, Australia},
  urldate = {2025-12-06},
  abstract = {Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).},
  file = {/home/arthings/Zotero/storage/4SE2P9H6/Gal et al. - 2017 - Deep Bayesian active learning with image data.pdf}
}

@techreport{gaujalExploitingJobVariability2019,
  type = {Research {{Report}}},
  title = {Exploiting {{Job Variability}} to {{Minimize Energy Consumption}} under {{Real-Time Constraints}}},
  author = {Gaujal, Bruno and Girault, Alain and Plassart, St{\'e}phan},
  year = 2019,
  month = nov,
  number = {RR-9300},
  pages = {23},
  institution = {Inria Grenoble Rh\^one-Alpes, Universit\'e de Grenoble ; Universit\'e Grenoble - Alpes},
  urldate = {2025-12-06},
  abstract = {This paper proposes a Markov Decision Process (MDP) approach to compute the optimal on-line speed scaling policy that minimizes the energy consumption of a single processor executing a finite or infinite set of jobs with real-time constraints, in the non-clairvoyant case,i.e., when the actual execution time of the jobs is unknown when they are released. In real life applications, it is common at release time to know only the Worst-Case Execution Time of a job, and the actual execution time of this job is only discovered when it finishes. Choosing the processor speed purely in function of the Worst-Case Execution Time is sub-optimal. When the probability distribution of the actual execution time is known, it is possible to exploit this knowledge to choose a lower processor speed so as to minimize the expected energy consumption (while still guaranteeing that all jobs meet their deadline). Our MDP solution solves this problem optimally with discrete processor speeds. Compared with approaches from the literature, the gain offered by the new policy ranges from a few percent when the variability of job characteristics is small, tomore than 50\%when the job execution time distributions are far from their worst case.},
  keywords = {Dynamic Voltage & Frequency Scaling,Markov Decision Process,Optimization,Real-Time Systems},
  file = {/home/arthings/Zotero/storage/3CMQS6LU/Gaujal et al. - 2019 - Exploiting Job Variability to Minimize Energy Consumption under Real-Time Constraints.pdf}
}

@misc{guidezERDEEntropyRegularizedDistillation2025,
  title = {{{ERDE}}: {{Entropy-Regularized Distillation}} for {{Early-exit}}},
  shorttitle = {{{ERDE}}},
  author = {Guidez, Martial and Duffner, Stefan and Alpou, Yannick and R{\"o}th, Oscar and Garcia, Christophe},
  year = 2025,
  month = oct,
  journal = {arXiv.org},
  urldate = {2025-12-06},
  abstract = {Although deep neural networks and in particular Convolutional Neural Networks have demonstrated state-of-the-art performance in image classification with relatively high efficiency, they still exhibit high computational costs, often rendering them impractical for real-time and edge applications. Therefore, a multitude of compression techniques have been developed to reduce these costs while maintaining accuracy. In addition, dynamic architectures have been introduced to modulate the level of compression at execution time, which is a desirable property in many resource-limited application scenarios. The proposed method effectively integrates two well-established optimization techniques: early exits and knowledge distillation, where a reduced student early-exit model is trained from a more complex teacher early-exit model. The primary contribution of this research lies in the approach for training the student early-exit model. In comparison to the conventional Knowledge Distillation loss, our approach incorporates a new entropy-based loss for images where the teacher's classification was incorrect. The proposed method optimizes the trade-off between accuracy and efficiency, thereby achieving significant reductions in computational complexity without compromising classification performance. The validity of this approach is substantiated by experimental results on image classification datasets CIFAR10, CIFAR100 and SVHN, which further opens new research perspectives for Knowledge Distillation in other contexts.},
  howpublished = {https://arxiv.org/abs/2510.04856v1},
  langid = {english},
  file = {/home/arthings/Zotero/storage/6DQEHTJU/Guidez et al. - 2025 - ERDE Entropy-Regularized Distillation for Early-exit.pdf}
}

@misc{hacohenActiveLearningBudget2022,
  title = {Active {{Learning}} on a {{Budget}}: {{Opposite Strategies Suit High}} and {{Low Budgets}}},
  shorttitle = {Active {{Learning}} on a {{Budget}}},
  author = {Hacohen, Guy and Dekel, Avihu and Weinshall, Daphna},
  year = 2022,
  month = jun,
  number = {arXiv:2202.02794},
  eprint = {2202.02794},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.02794},
  urldate = {2025-12-06},
  abstract = {Investigating active learning, we focus on the relation between the number of labeled examples (budget size), and suitable querying strategies. Our theoretical analysis shows a behavior reminiscent of phase transition: typical examples are best queried when the budget is low, while unrepresentative examples are best queried when the budget is large. Combined evidence shows that a similar phenomenon occurs in common classification models. Accordingly, we propose TypiClust -- a deep active learning strategy suited for low budgets. In a comparative empirical investigation of supervised learning, using a variety of architectures and image datasets, TypiClust outperforms all other active learning strategies in the low-budget regime. Using TypiClust in the semi-supervised framework, performance gets an even more significant boost. In particular, state-of-the-art semi-supervised methods trained on CIFAR-10 with 10 labeled examples selected by TypiClust, reach 93.2\% accuracy -- an improvement of 39.4\% over random selection. Code is available at https://github.com/avihu111/TypiClust.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/arthings/Zotero/storage/UDLBDT6U/Hacohen et al. - 2022 - Active Learning on a Budget Opposite Strategies Suit High and Low Budgets.pdf;/home/arthings/Zotero/storage/JI6QEYL6/2202.html}
}

@misc{kambaleAutoscalingServerlessPlatforms2025,
  title = {Autoscaling in {{Serverless Platforms}} via {{Online Learning}} with {{Convergence Guarantees}}},
  author = {Kambale, Abednego Wamuhindo and Anselmi, Jonatha and Ardagna, Danilo and Gaujal, Bruno},
  year = 2025,
  urldate = {2025-12-06},
  abstract = {{$<$}div{$><$}p{$>$}As the adoption of serverless computing platforms continue to grow, designing autoscaling policies that strike the right balance between energy efficiency and user-perceived performance has become a central challenge. In this work, we propose an online learning algorithm with theoretical convergence guarantees that dynamically tunes control parameters in a serverless autoscaling environment. The proposed algorithm, grounded in stochastic gradient descent, learns online-during the actual operation of the platform-the optimal values of three key control parameters: (i) the target stock size of prewarmed (idle) functions, (ii) the threshold triggering provisioning actions, and (iii) the expiration rate of idle resources. We prove that, under Markovian dynamics, the algorithm converges to the parameter set that minimizes a cost function capturing the tradeoff between energy consumption and response latency. In addition, we demonstrate that its structure naturally supports parallelization, significantly accelerating convergence.{$<$}/p{$><$}p{$>$}Extensive numerical experiments show that our method outperforms existing baselines, including recent deep learning-based approaches, even under non-Markovian settings-highlighting both its robustness and practical viability for next-generation serverless infrastructures.{$<$}/p{$><$}/div{$>$}},
  langid = {english},
  file = {/home/arthings/Zotero/storage/R9TRV5IJ/Kambale et al. - 2025 - Autoscaling in Serverless Platforms via Online Learning with Convergence Guarantees.pdf}
}

@article{mimouniDomainSpecificKnowledge2020,
  title = {Domain {{Specific Knowledge Graph Embedding}} for {{Analogical Link Discovery}}},
  author = {Mimouni, Nada and Moissinac, Jean-Claude and Tuan, Anh},
  year = 2020,
  month = jun,
  journal = {International Journal On Advances in Intelligent Systems},
  publisher = {IARIA},
  urldate = {2025-12-06},
  abstract = {General purpose knowledge bases such as DBpedia and Wikidata are valuable resources for various AI tasks. They describe real-world facts as entities and relations between them and they are typically incomplete. Knowledge base completion refers to the task of adding new missing links between entities to build new triples. In this work, we propose an approach for discovering implicit triples using observed ones in the incomplete graph leveraging analogy structures deducted from a knowledge graph embedding model. We use a neural language modelling approach where semantic regularities between words are preserved, which we adapt to entities and relations. We consider domain specific views from large input graphs as the basis for the training, which we call context graphs, as a reduced and meaningful context for a set of entities from a given domain. Results show that analogical inferences in the projected vector space is relevant to a link prediction task in domain knowledge bases.},
  keywords = {Analogy structure,Context graph,Domain knowledge base,Entity embedding,Facts discovery,Neural language model},
  file = {/home/arthings/Zotero/storage/ZYKKNTYK/Mimouni et al. - 2020 - Domain Specific Knowledge Graph Embedding for Analogical Link Discovery.pdf}
}

@misc{munjalRobustReproducibleActive2022,
  title = {Towards {{Robust}} and {{Reproducible Active Learning Using Neural Networks}}},
  author = {Munjal, Prateek and Hayat, Nasir and Hayat, Munawar and Sourati, Jamshid and Khan, Shadab},
  year = 2022,
  month = jun,
  number = {arXiv:2002.09564},
  eprint = {2002.09564},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2002.09564},
  urldate = {2025-12-06},
  abstract = {Active learning (AL) is a promising ML paradigm that has the potential to parse through large unlabeled data and help reduce annotation cost in domains where labeling data can be prohibitive. Recently proposed neural network based AL methods use different heuristics to accomplish this goal. In this study, we demonstrate that under identical experimental settings, different types of AL algorithms (uncertainty based, diversity based, and committee based) produce an inconsistent gain over random sampling baseline. Through a variety of experiments, controlling for sources of stochasticity, we show that variance in performance metrics achieved by AL algorithms can lead to results that are not consistent with the previously reported results. We also found that under strong regularization, AL methods show marginal or no advantage over the random sampling baseline under a variety of experimental conditions. Finally, we conclude with a set of recommendations on how to assess the results using a new AL algorithm to ensure results are reproducible and robust under changes in experimental conditions. We share our codes to facilitate AL evaluations. We believe our findings and recommendations will help advance reproducible research in AL using neural networks. We open source our code at https://github.com/PrateekMunjal/TorchAL},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/arthings/Zotero/storage/VV3DRWEG/Munjal et al. - 2022 - Towards Robust and Reproducible Active Learning Using Neural Networks.pdf;/home/arthings/Zotero/storage/CV9LTHIZ/2002.html}
}

@article{panUnifyingLargeLanguage2024,
  title = {Unifying {{Large Language Models}} and {{Knowledge Graphs}}: {{A Roadmap}}},
  shorttitle = {Unifying {{Large Language Models}} and {{Knowledge Graphs}}},
  author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  year = 2024,
  month = jul,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {7},
  eprint = {2306.08302},
  primaryclass = {cs},
  pages = {3580--3599},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2024.3352100},
  urldate = {2025-12-06},
  abstract = {Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/arthings/Zotero/storage/FK3Z3E9B/Pan et al. - 2024 - Unifying Large Language Models and Knowledge Graphs A Roadmap.pdf;/home/arthings/Zotero/storage/WBEVIEJE/2306.html}
}

@misc{romanoClassificationValidAdaptive2020,
  title = {Classification with {{Valid}} and {{Adaptive Coverage}}},
  author = {Romano, Yaniv and Sesia, Matteo and Cand{\`e}s, Emmanuel J.},
  year = 2020,
  month = jun,
  number = {arXiv:2006.02544},
  eprint = {2006.02544},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.02544},
  urldate = {2025-12-06},
  abstract = {Conformal inference, cross-validation+, and the jackknife+ are hold-out methods that can be combined with virtually any machine learning algorithm to construct prediction sets with guaranteed marginal coverage. In this paper, we develop specialized versions of these techniques for categorical and unordered response labels that, in addition to providing marginal coverage, are also fully adaptive to complex data distributions, in the sense that they perform favorably in terms of approximate conditional coverage compared to alternative methods. The heart of our contribution is a novel conformity score, which we explicitly demonstrate to be powerful and intuitive for classification problems, but whose underlying principle is potentially far more general. Experiments on synthetic and real data demonstrate the practical value of our theoretical guarantees, as well as the statistical advantages of the proposed methods over the existing alternatives.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/arthings/Zotero/storage/QLKNFGV6/Romano et al. - 2020 - Classification with Valid and Adaptive Coverage.pdf;/home/arthings/Zotero/storage/FKFS3BMN/2006.html}
}

@misc{senerActiveLearningConvolutional2018,
  title = {Active {{Learning}} for {{Convolutional Neural Networks}}: {{A Core-Set Approach}}},
  shorttitle = {Active {{Learning}} for {{Convolutional Neural Networks}}},
  author = {Sener, Ozan and Savarese, Silvio},
  year = 2018,
  month = jun,
  number = {arXiv:1708.00489},
  eprint = {1708.00489},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1708.00489},
  urldate = {2025-12-06},
  abstract = {Convolutional neural networks (CNNs) have been successfully applied to many recognition and learning tasks using a universal recipe; training a deep model on a very large dataset of supervised examples. However, this approach is rather restrictive in practice since collecting a large set of labeled images is very expensive. One way to ease this problem is coming up with smart ways for choosing images to be labelled from a very large collection (ie. active learning). Our empirical study suggests that many of the active learning heuristics in the literature are not effective when applied to CNNs in batch setting. Inspired by these limitations, we define the problem of active learning as core-set selection, ie. choosing set of points such that a model learned over the selected subset is competitive for the remaining data points. We further present a theoretical result characterizing the performance of any selected subset using the geometry of the datapoints. As an active learning algorithm, we choose the subset which is expected to yield best result according to our characterization. Our experiments show that the proposed method significantly outperforms existing approaches in image classification experiments by a large margin.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/arthings/Zotero/storage/8NFDGARK/Sener et Savarese - 2018 - Active Learning for Convolutional Neural Networks A Core-Set Approach.pdf;/home/arthings/Zotero/storage/G7UAX5WS/1708.html}
}

@inproceedings{zhaoFeedbackControlOnline2019,
  title = {Feedback {{Control}} for {{Online Training}} of {{Neural Networks}}},
  booktitle = {{{IEEE Conference}} on {{Control Technology}} and {{Applications}}},
  author = {Zhao, Zilong and Cerf, Sophie and Robu, Bogdan and Marchand, Nicolas},
  year = 2019,
  month = aug,
  address = {Hong Kong, China},
  urldate = {2025-12-06},
  abstract = {Convolutional neural networks (CNNs) are commonly used for image classification tasks, raising the challenge of their application on data flows. During their training, adaptation is often performed by tuning the learning rate. Usual learning rate strategies are time-based i.e. monotonously decreasing. In this paper, we advocate switching to a performance-based adaptation, in order to improve the learning efficiency. We present E (Exponential)/PD (Proportional Derivative)-Control, a conditional learning rate strategy that combines a feedback PD controller based on the CNN loss function, with an exponential control signal to smartly boost the learning and adapt the PD parameters. Stability proof is provided as well as an experimental evaluation using two state of the art image datasets (CIFAR-10 and Fashion-MNIST). Results show better performances than the related works (faster network accuracy growth reaching higher levels) and robustness of the E/PD- Control regarding its parametrization.},
  file = {/home/arthings/Zotero/storage/6U5TFI5Z/Zhao et al. - 2019 - Feedback Control for Online Training of Neural Networks.pdf}
}

@misc{zhouSetupKitEfficientMultiCorner2025,
  title = {{{SetupKit}}: {{Efficient Multi-Corner Setup}}/{{Hold Time Characterization Using Bias-Enhanced Interpolation}} and {{Active Learning}}},
  shorttitle = {{{SetupKit}}},
  author = {Zhou, Junzhuo and Wang, Ziwen and Xia, Haoxuan and Yan, Yuxin and Zhu, Chengyu and Lin, Ting-Jung and Xing, Wei and He, Lei},
  year = 2025,
  month = nov,
  number = {arXiv:2512.00044},
  eprint = {2512.00044},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2512.00044},
  urldate = {2025-12-06},
  abstract = {Accurate setup/hold time characterization is crucial for modern chip timing closure, but its reliance on potentially millions of SPICE simulations across diverse process-voltagetemperature (PVT) corners creates a major bottleneck, often lasting weeks or months. Existing methods suffer from slow search convergence and inefficient exploration, especially in the multi-corner setting. We introduce SetupKit, a novel framework designed to break this bottleneck using statistical intelligence, circuit analysis and active learning (AL). SetupKit integrates three key innovations: BEIRA, a bias-enhanced interpolation search derived from statistical error modeling to accelerate convergence by overcoming stagnation issues, initial search interval estimation by circuit analysis and AL strategy using Gaussian Process. This AL component intelligently learns PVT-timing correlations, actively guiding the expensive simulations to the most informative corners, thus minimizing redundancy in multicorner characterization. Evaluated on industrial 22nm standard cells across 16 PVT corners, SetupKit demonstrates a significant 2.4x overall CPU time reduction (from 720 to 290 days on a single core) compared to standard practices, drastically cutting characterization time. SetupKit offers a principled, learningbased approach to library characterization, addressing a critical EDA challenge and paving the way for more intelligent simulation management.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning},
  file = {/home/arthings/Zotero/storage/TZBLJ8MV/Zhou et al. - 2025 - SetupKit Efficient Multi-Corner SetupHold Time Characterization Using Bias-Enhanced Interpolation.pdf;/home/arthings/Zotero/storage/JMHLS9FF/2512.html}
}
